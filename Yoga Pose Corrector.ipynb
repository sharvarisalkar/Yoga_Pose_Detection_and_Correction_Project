{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 232\u001b[0m\n\u001b[0;32m    230\u001b[0m message_lines \u001b[38;5;241m=\u001b[39m current_pose[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(message_lines):\n\u001b[1;32m--> 232\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mputText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransition_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m               \u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFONT_HERSHEY_SIMPLEX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m reference_start_time \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:  \u001b[38;5;66;03m# Show transition for 3 seconds\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     show_reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Pose detector\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Custom drawing specs\n",
    "valid_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)  # Green\n",
    "invalid_drawing_spec = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)  # Red\n",
    "\n",
    "# Load reference images from local files\n",
    "try:\n",
    "    ref_img_size = (300, 300)\n",
    "    tree_pose_img = cv2.imread(\"tree_pose.jpg\")\n",
    "    downward_dog_img = cv2.imread(\"downward_dog.jpg\")\n",
    "    goddess_pose_img = cv2.imread(\"goddess_pose.jpg\")\n",
    "    lotus_pose_img = cv2.imread(\"lotus_pose.jpg\")\n",
    "    butterfly_pose_img = cv2.imread(\"butterfly_pose.jpg\")\n",
    "    easy_pose_img = cv2.imread(\"easy_pose.jpg\")\n",
    "    \n",
    "    # Resize images\n",
    "    tree_pose_img = cv2.resize(tree_pose_img, ref_img_size) if tree_pose_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "    downward_dog_img = cv2.resize(downward_dog_img, ref_img_size) if downward_dog_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "    goddess_pose_img = cv2.resize(goddess_pose_img, ref_img_size) if goddess_pose_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "    lotus_pose_img = cv2.resize(lotus_pose_img, ref_img_size) if lotus_pose_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "    butterfly_pose_img = cv2.resize(butterfly_pose_img, ref_img_size) if butterfly_pose_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "    easy_pose_img = cv2.resize(easy_pose_img, ref_img_size) if easy_pose_img is not None else np.zeros((*ref_img_size, 3), dtype=np.uint8)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading images: {e}\")\n",
    "    blank_img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "    tree_pose_img = downward_dog_img = goddess_pose_img = lotus_pose_img = butterfly_pose_img = easy_pose_img = blank_img\n",
    "\n",
    "# Pose sequence\n",
    "poses = [\n",
    "    {\"name\": \"Stand Up\", \"image\": None, \"completed\": False, \"is_transition\": True, \"message\": \"Stand Up straight\\nGet ready for standing poses\"},\n",
    "    {\"name\": \"Tree Pose\", \"image\": tree_pose_img, \"completed\": False},\n",
    "    {\"name\": \"Downward Dog Pose\", \"image\": downward_dog_img, \"completed\": False},\n",
    "    {\"name\": \"Goddess Pose\", \"image\": goddess_pose_img, \"completed\": False},\n",
    "    {\"name\": \"Sit Down\", \"image\": None, \"completed\": False, \"is_transition\": True, \"message\": \"Sit Down comfortably\\nGet ready for seated poses\"},\n",
    "    {\"name\": \"Lotus Pose\", \"image\": lotus_pose_img, \"completed\": False},\n",
    "    {\"name\": \"Butterfly Pose\", \"image\": butterfly_pose_img, \"completed\": False},\n",
    "    {\"name\": \"Easy Pose\", \"image\": easy_pose_img, \"completed\": False, \"is_meditation\": True}\n",
    "]\n",
    "\n",
    "# State variables\n",
    "current_pose_index = 0\n",
    "round_number = 1\n",
    "show_reference = True\n",
    "reference_start_time = time.time()\n",
    "feedback_message = \"\"\n",
    "feedback_timer = 0\n",
    "pose_validated = False\n",
    "pose_hold_start = 0\n",
    "pose_hold_duration = 3.0  # Increased hold time to 3 seconds\n",
    "transition_delay = 1.0\n",
    "meditation_start = 0\n",
    "meditation_duration = 60\n",
    "breath_cycle = \"Breathe In\"\n",
    "last_breath_change = 0\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])\n",
    "    b = np.array([b.x, b.y])\n",
    "    c = np.array([c.x, c.y])\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "def check_pose(landmarks, target_pose):\n",
    "    feedback = []\n",
    "    all_correct = True\n",
    "    \n",
    "    # Get landmarks\n",
    "    nose = landmarks[mp_pose.PoseLandmark.NOSE.value]\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    right_elbow = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "    right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "    left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "    right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "    left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "    right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "\n",
    "    # Calculate angles\n",
    "    left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "    if target_pose == \"Stand Up\":\n",
    "        standing = (left_hip.y < left_shoulder.y + 0.1) and (right_hip.y < right_shoulder.y + 0.1)\n",
    "        if not standing:\n",
    "            feedback.append(\"Stand up straight\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Tree Pose\":\n",
    "        foot_on_thigh = ((left_ankle.y < left_knee.y and abs(left_ankle.x - right_hip.x) < 0.15)) or \\\n",
    "                        (right_ankle.y < right_knee.y and abs(right_ankle.x - left_hip.x) < 0.15)\n",
    "        if not foot_on_thigh:\n",
    "            feedback.append(\"Place foot on opposite thigh\")\n",
    "            all_correct = False\n",
    "        \n",
    "        hands_together = (abs(left_wrist.x - right_wrist.x) < 0.1 and \n",
    "                         abs(left_wrist.y - right_wrist.y) < 0.1 and \n",
    "                         left_wrist.y < nose.y)\n",
    "        if not hands_together:\n",
    "            feedback.append(\"Bring hands together above head\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Downward Dog Pose\":\n",
    "        hips_raised = (left_hip.y < left_shoulder.y) and (right_hip.y < right_shoulder.y)\n",
    "        if not hips_raised:\n",
    "            feedback.append(\"Raise your hips higher\")\n",
    "            all_correct = False\n",
    "        \n",
    "        legs_straight = (left_knee_angle > 160) and (right_knee_angle > 160)\n",
    "        if not legs_straight:\n",
    "            feedback.append(\"Straighten your legs\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Goddess Pose\":\n",
    "        knees_bent = (left_knee_angle < 120) and (right_knee_angle < 120)\n",
    "        knees_wide = abs(left_knee.x - right_knee.x) > abs(left_hip.x - right_hip.x)\n",
    "        if not knees_bent:\n",
    "            feedback.append(\"Bend your knees more\")\n",
    "            all_correct = False\n",
    "        if not knees_wide:\n",
    "            feedback.append(\"Widen your stance\")\n",
    "            all_correct = False\n",
    "        \n",
    "        arms_bent = (left_elbow_angle < 90) and (right_elbow_angle < 90)\n",
    "        arms_height = abs(left_wrist.y - left_shoulder.y) < 0.15\n",
    "        if not arms_bent:\n",
    "            feedback.append(\"Bend your elbows\")\n",
    "            all_correct = False\n",
    "        if not arms_height:\n",
    "            feedback.append(\"Raise arms to shoulder height\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Sit Down\":\n",
    "        sitting = (left_hip.y > left_knee.y) and (right_hip.y > right_knee.y)\n",
    "        if not sitting:\n",
    "            feedback.append(\"Sit down comfortably\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Lotus Pose\":\n",
    "        left_foot_on_right_thigh = (left_ankle.y < right_knee.y and abs(left_ankle.x - right_hip.x) < 0.15)\n",
    "        right_foot_on_left_thigh = (right_ankle.y < left_knee.y and abs(right_ankle.x - left_hip.x) < 0.15)\n",
    "        \n",
    "        if not (left_foot_on_right_thigh or right_foot_on_left_thigh):\n",
    "            feedback.append(\"Place at least one foot on opposite thigh\")\n",
    "            all_correct = False\n",
    "            \n",
    "        spine_straight = (abs(left_shoulder.x - left_hip.x) < 0.1) and (abs(right_shoulder.x - right_hip.x) < 0.1)\n",
    "        if not spine_straight:\n",
    "            feedback.append(\"Keep spine straight\")\n",
    "            all_correct = False\n",
    "            \n",
    "        hands_on_knees = ((abs(left_wrist.x - left_knee.x) < 0.15 and abs(left_wrist.y - left_knee.y) < 0.15) and \n",
    "                         (abs(right_wrist.x - right_knee.x) < 0.15 and abs(right_wrist.y - right_knee.y) < 0.15))\n",
    "        \n",
    "        hands_prayer = (abs(left_wrist.x - right_wrist.x) < 0.1 and abs(left_wrist.y - right_wrist.y) < 0.1)\n",
    "        \n",
    "        if not (hands_on_knees or hands_prayer):\n",
    "            feedback.append(\"Place hands on knees or in prayer position\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Butterfly Pose\":\n",
    "        knees_bent = (left_knee_angle < 90) and (right_knee_angle < 90)\n",
    "        feet_together = abs(left_ankle.x - right_ankle.x) < 0.1\n",
    "        \n",
    "        if not knees_bent:\n",
    "            feedback.append(\"Bend your knees more\")\n",
    "            all_correct = False\n",
    "        if not feet_together:\n",
    "            feedback.append(\"Bring feet together\")\n",
    "            all_correct = False\n",
    "            \n",
    "        hands_on_feet = ((abs(left_wrist.x - left_ankle.x) < 0.15 and abs(left_wrist.y - left_ankle.y) < 0.15)) and \\\n",
    "                       ((abs(right_wrist.x - right_ankle.x) < 0.15 and abs(right_wrist.y - right_ankle.y) < 0.15))\n",
    "        \n",
    "        if not hands_on_feet:\n",
    "            feedback.append(\"Hold your feet with hands\")\n",
    "            all_correct = False\n",
    "\n",
    "    elif target_pose == \"Easy Pose\":\n",
    "        legs_crossed = (left_knee.x > right_ankle.x) and (right_knee.x < left_ankle.x)\n",
    "        if not legs_crossed:\n",
    "            feedback.append(\"Cross your legs comfortably\")\n",
    "            all_correct = False\n",
    "            \n",
    "        spine_straight = (abs(left_shoulder.x - left_hip.x) < 0.1) and (abs(right_shoulder.x - right_hip.x) < 0.1)\n",
    "        if not spine_straight:\n",
    "            feedback.append(\"Keep spine straight\")\n",
    "            all_correct = False\n",
    "\n",
    "    return all_correct, feedback\n",
    "\n",
    "# Main loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    current_pose = poses[current_pose_index]\n",
    "    \n",
    "    # Special handling for transition poses\n",
    "    if 'is_transition' in current_pose and current_pose['is_transition']:\n",
    "        if show_reference:\n",
    "            # Create a clean frame for transition message\n",
    "            transition_frame = np.zeros_like(frame)\n",
    "            cv2.putText(transition_frame, current_pose['name'].upper(), \n",
    "                       (frame.shape[1]//2-100, frame.shape[0]//2-50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)\n",
    "            \n",
    "            # Split message into lines if it contains newline characters\n",
    "            message_lines = current_pose['message'].split('\\n')\n",
    "            for i, line in enumerate(message_lines):\n",
    "                cv2.putText(transition_frame, line, \n",
    "                           (frame.shape[1]//2-200, frame.shape[0]//2 + 30 + i*40), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "            \n",
    "            if time.time() - reference_start_time > 3:  # Show transition for 3 seconds\n",
    "                show_reference = False\n",
    "                pose_validated = True\n",
    "                current_pose['completed'] = True\n",
    "                current_pose_index = (current_pose_index + 1) % len(poses)\n",
    "                show_reference = True\n",
    "                reference_start_time = time.time()\n",
    "            \n",
    "            cv2.imshow(\"Yoga Pose Detection\", transition_frame)\n",
    "            cv2.waitKey(1)\n",
    "            continue\n",
    "    \n",
    "    # Show reference image first\n",
    "    if show_reference:\n",
    "        if current_pose['image'] is not None:\n",
    "            # Create a clean frame for reference image\n",
    "            ref_frame = np.zeros_like(frame)\n",
    "            cv2.putText(ref_frame, f\"ROUND {round_number}: Match this pose\", (50, 50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.putText(ref_frame, current_pose['name'], (50, 100), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            \n",
    "            # Center reference image\n",
    "            h, w = current_pose['image'].shape[:2]\n",
    "            x = (frame.shape[1] - w) // 2\n",
    "            y = (frame.shape[0] - h) // 2\n",
    "            ref_frame[y:y+h, x:x+w] = current_pose['image']\n",
    "        else:\n",
    "            ref_frame = np.zeros_like(frame)\n",
    "            cv2.putText(ref_frame, current_pose['name'], (frame.shape[1]//2-100, frame.shape[0]//2), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        \n",
    "        if time.time() - reference_start_time > 2:  # Show reference for 2 seconds\n",
    "            show_reference = False\n",
    "            pose_validated = False\n",
    "            pose_hold_start = 0\n",
    "            if 'is_meditation' in current_pose and current_pose['is_meditation']:\n",
    "                meditation_start = time.time()\n",
    "                last_breath_change = time.time()\n",
    "        \n",
    "        cv2.imshow(\"Yoga Pose Detection\", ref_frame)\n",
    "        cv2.waitKey(1)\n",
    "        continue\n",
    "    \n",
    "    # Process pose detection\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    pose_valid = False\n",
    "    feedback = []\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        pose_valid, feedback = check_pose(landmarks, current_pose['name'])\n",
    "        \n",
    "        # Draw landmarks with appropriate color\n",
    "        if pose_valid:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                valid_drawing_spec, valid_drawing_spec\n",
    "            )\n",
    "            # Start or continue hold timer\n",
    "            if pose_hold_start == 0:\n",
    "                pose_hold_start = time.time()\n",
    "        else:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                invalid_drawing_spec, invalid_drawing_spec\n",
    "            )\n",
    "            pose_hold_start = 0\n",
    "            pose_validated = False\n",
    "\n",
    "    # Special meditation handling for Easy Pose\n",
    "    if 'is_meditation' in current_pose and current_pose['is_meditation'] and pose_valid:\n",
    "        current_time = time.time()\n",
    "        meditation_elapsed = current_time - meditation_start\n",
    "        remaining_time = max(0, meditation_duration - meditation_elapsed)\n",
    "        \n",
    "        # Change breath message every 3 seconds\n",
    "        if current_time - last_breath_change > 3:\n",
    "            breath_cycle = \"Breathe Out\" if breath_cycle == \"Breathe In\" else \"Breathe In\"\n",
    "            last_breath_change = current_time\n",
    "        \n",
    "        # Draw meditation timer\n",
    "        cv2.rectangle(frame, (50, 70), (int(50 + (frame.shape[1]-100) * (meditation_elapsed/meditation_duration)), 90), (0, 255, 255), -1)\n",
    "        cv2.rectangle(frame, (50, 70), (frame.shape[1]-50, 90), (255, 255, 255), 1)\n",
    "        cv2.putText(frame, f\"Meditation: {int(remaining_time)}s remaining\", (50, 65), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Draw breath instruction in center\n",
    "        cv2.putText(frame, breath_cycle, (frame.shape[1]//2-80, frame.shape[0]//2), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 200, 255), 3)\n",
    "        \n",
    "        # Complete meditation after duration\n",
    "        if meditation_elapsed >= meditation_duration:\n",
    "            pose_validated = True\n",
    "            current_pose['completed'] = True\n",
    "            feedback_message = \"Meditation Complete!\"\n",
    "            feedback_timer = time.time()\n",
    "            \n",
    "            # Check if all poses completed\n",
    "            if all(p['completed'] for p in poses):\n",
    "                # Show completion message\n",
    "                completion_frame = np.zeros_like(frame)\n",
    "                cv2.putText(completion_frame, \"FANTASTIC!\", (frame.shape[1]//2-150, frame.shape[0]//2-50), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)\n",
    "                cv2.putText(completion_frame, f\"You've completed Round {round_number}!\", \n",
    "                           (frame.shape[1]//2-250, frame.shape[0]//2+20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(completion_frame, \"Get ready for Round 2!\", \n",
    "                           (frame.shape[1]//2-200, frame.shape[0]//2+70), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.imshow(\"Yoga Pose Detection\", completion_frame)\n",
    "                cv2.waitKey(3000)\n",
    "                \n",
    "                # Reset for next round\n",
    "                round_number += 1\n",
    "                current_pose_index = 0\n",
    "                show_reference = True\n",
    "                reference_start_time = time.time()\n",
    "                for p in poses:\n",
    "                    p['completed'] = False\n",
    "                continue\n",
    "    else:\n",
    "        # Normal pose validation and transition logic\n",
    "        if pose_valid and not pose_validated:\n",
    "            if pose_hold_start > 0 and (time.time() - pose_hold_start) >= pose_hold_duration:\n",
    "                feedback_message = \"VALID POSE!\"\n",
    "                feedback_timer = time.time()\n",
    "                pose_validated = True\n",
    "                current_pose['completed'] = True\n",
    "                \n",
    "                time.sleep(transition_delay)\n",
    "                \n",
    "                # Move to next pose\n",
    "                current_pose_index = (current_pose_index + 1) % len(poses)\n",
    "                show_reference = True\n",
    "                reference_start_time = time.time()\n",
    "                pose_validated = False\n",
    "                \n",
    "                cv2.imshow(\"Yoga Pose Detection\", frame)\n",
    "                cv2.waitKey(1)\n",
    "                continue\n",
    "        elif not pose_valid:\n",
    "            if feedback:\n",
    "                feedback_message = \"INVALID: \" + \" | \".join(feedback[:2])\n",
    "                feedback_timer = time.time()\n",
    "\n",
    "    # Display current pose and status\n",
    "    status = \"VALID\" if pose_validated else (\"HOLDING\" if pose_valid and pose_hold_start > 0 else \"INVALID\")\n",
    "    text_color = (0, 255, 0) if status == \"VALID\" else (0, 165, 255) if status == \"HOLDING\" else (0, 0, 255)\n",
    "    \n",
    "    cv2.putText(frame, f\"{current_pose['name']}: {status}\", (50, 40), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
    "    \n",
    "    # Show round number\n",
    "    cv2.putText(frame, f\"Round: {round_number}\", (frame.shape[1] - 150, 40), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Show feedback message\n",
    "    if time.time() - feedback_timer < 2 and feedback_message:\n",
    "        cv2.putText(frame, feedback_message, (50, frame.shape[0] - 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)\n",
    "    \n",
    "    # Show pose hold progress if validating (not for meditation)\n",
    "    if pose_valid and not pose_validated and pose_hold_start > 0 and not ('is_meditation' in current_pose and current_pose['is_meditation']):\n",
    "        progress = min(1.0, (time.time() - pose_hold_start) / pose_hold_duration)\n",
    "        cv2.rectangle(frame, (50, 70), (int(50 + 200 * progress), 90), (0, 255, 0), -1)\n",
    "        cv2.rectangle(frame, (50, 70), (250, 90), (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Hold pose...\", (50, 65), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Show small reference in corner (if available)\n",
    "    if current_pose['image'] is not None:\n",
    "        ref_img = cv2.resize(current_pose['image'], (150, 150))\n",
    "        frame[10:160, frame.shape[1]-160:frame.shape[1]-10] = ref_img\n",
    "    \n",
    "    cv2.imshow(\"Yoga Pose Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
